[Corpus]
train_source=sample_data/tiny.in
train_target=sample_data/tiny.out
dev_source=sample_data/tiny.in
dev_target=sample_data/tiny.out
test_source=sample_data/tiny.in
test_target=sample_data/tiny.out

[Model]
rnn_cell=lstm
source_vocabulary=32
target_vocabulary=32
embedding=64
rnn_hidden=64
encoder_type=bidirectional
decoder_type=forward
attention_type=mlp
attention_hidden=64

[Train]
adam_alpha=0.001
adam_beta1=0.9
adam_beta2=0.999
adam_eps=1e-8
max_length=16
num_words_in_batch=32
max_iteration=10000
evaluation_interval=100
random_seed=12345
