[Global]
forward_memory_mb=256
backward_memory_mb=256
parameter_memory_mb=256
random_seed=12345
backend_random_seed=12345

[Corpus]
train_source=sample_data/tiny.in
train_target=sample_data/tiny.out
dev_source=sample_data/tiny.in
dev_target=sample_data/tiny.out
test_source=sample_data/tiny.in
test_target=sample_data/tiny.out

[Model]
source_vocabulary=30
target_vocabulary=33
source_embedding=67
target_embedding=68
encoder_hidden=63
decoder_hidden=64
attention_type=mlp
attention_hidden=62

[Train]
adam_alpha=0.001
adam_beta1=0.9
adam_beta2=0.999
adam_eps=1e-8
max_length=16
max_length_ratio=1.5
num_words_in_batch=32
max_iteration=10000
evaluation_interval=100
