[Global]
forward_memory_mb=2048
backward_memory_mb=2048
parameter_memory_mb=2048
random_seed=12345
backend_random_seed=12345

[Corpus]
train_source=submodules/small_parallel_enja/train.en
train_target=submodules/small_parallel_enja/train.ja
dev_source=submodules/small_parallel_enja/dev.en
dev_target=submodules/small_parallel_enja/dev.ja
test_source=submodules/small_parallel_enja/test.en
test_target=submodules/small_parallel_enja/test.ja

[Model]
source_vocabulary=4096
target_vocabulary=4096
embedding=512
rnn_hidden=512
attention_type=mlp
attention_hidden=512

[Train]
adam_alpha=0.001
adam_beta1=0.9
adam_beta2=0.999
adam_eps=1e-8
max_length=64
max_length_ratio=1.5
num_words_in_batch=2048
max_iteration=10000
evaluation_interval=100
